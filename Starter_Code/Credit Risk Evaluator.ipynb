{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located in the Challenge Files Folder:\n",
    "\n",
    "* `lending_data.csv`\n",
    "\n",
    "Import the data using Pandas. Display the resulting dataframe to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "lending_data = pd.read_csv(\"Resources/lending_data.csv\")\n",
    "lending_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77536 entries, 0 to 77535\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   loan_size         77536 non-null  float64\n",
      " 1   interest_rate     77536 non-null  float64\n",
      " 2   borrower_income   77536 non-null  int64  \n",
      " 3   debt_to_income    77536 non-null  float64\n",
      " 4   num_of_accounts   77536 non-null  int64  \n",
      " 5   derogatory_marks  77536 non-null  int64  \n",
      " 6   total_debt        77536 non-null  int64  \n",
      " 7   loan_status       77536 non-null  int64  \n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "#check the null count and data types\n",
    "lending_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
    "\n",
    "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "In this Predictive model analysis, my prediction is Logistic regression will do better than a Random Forests classifier. Since we have data and qualifiers which can provide enough indicators for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  \n",
       "0                 1       22800  \n",
       "1                 0       13600  \n",
       "2                 0       16100  \n",
       "3                 1       22700  \n",
       "4                 1       23000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = lending_data['loan_status'].values\n",
    "X = lending_data.drop('loan_status', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=27)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, Fit and Compare Models\n",
    "\n",
    "Create a Logistic Regression model, fit it to the data, and print the model's score. Do the same for a Random Forest Classifier. You may choose any starting hyperparameters you like. \n",
    "\n",
    "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the designated markdown cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Logistic Regression Model helps predicting a binary outcomes like 'Yes' or 'No' values based on observations in the selected dataset. In this project we are looking to predict the lender to approve or decline the loan based on the application requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=10000)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Score: 0.9916597881414225\n",
      "Test Data Score: 0.9923648369789517\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "print(f\"Train Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Test Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18656,    85],\n",
       "       [   63,   580]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = y_test\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966828312009905\n"
     ]
    }
   ],
   "source": [
    "#Determine accuracy\n",
    "tp,tn,fp,fn = confusion_matrix(y_true, y_pred).ravel()\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn) \n",
    "# (18656 + 580) / (18656 + 580 + 63 + 85)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18741\n",
      "           1       0.87      0.90      0.89       643\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.95      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier\n",
    "random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9974893382858715\n",
      "Test Score: 0.9908171687990095\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Train Score: {classifier.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {classifier.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.34686541e-01 2.35103115e-01 1.79984803e-01 1.63830590e-01\n",
      " 1.34594557e-01 1.32680633e-04 1.51667713e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = classifier.feature_importances_\n",
    "print(features)\n",
    "plt.bar(x = range(len(features)), height=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(classifier)\n",
    "sel.fit(X_train_scaled, y_train)\n",
    "sel.get_support()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Logistic regression model and Random forest classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trish\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9676537350392076\n",
      "Test Score: 0.9680664465538589\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "print(f'Train Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    " As it can be seen that both models testing score have not significantly different. The LRM has a testing score of 0.9923 while the RFM's testing score is 0.9908. My prediction seems not so accurate.However, if considering the training score, the one displayed with the Random forest model is higher than the one detected with the Logistic regression model. Overall, either of the models can do the analysis with appropriate accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Which model performed better? How does that compare to your prediction? Replace the text in this markdown cell with your answers to these questions.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8197f22973c5407e9a219684849df8431dbbde0e1dd826ce45504039b1261de2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
